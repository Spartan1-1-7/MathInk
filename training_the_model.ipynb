{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3bb679da",
   "metadata": {},
   "source": [
    "#### Importing Lib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ae62280",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow.keras.backend as K\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86229b5",
   "metadata": {},
   "source": [
    "#### Loading the CSV files and preparing a vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ab962a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size: 93\n",
      "Example mapping: [(' ', 0), ('!', 1), ('\"', 2), ('#', 3), ('&', 4), (\"'\", 5), ('(', 6), (')', 7), ('*', 8), ('+', 9)]\n"
     ]
    }
   ],
   "source": [
    "# Paths\n",
    "dataset_path = 'lm2LaTeX-100K'\n",
    "images_path = os.path.join(dataset_path, 'processed_img')\n",
    "\n",
    "# Load CSV files\n",
    "train_df = pd.read_csv(os.path.join(dataset_path, 'im2latex_train.csv'))\n",
    "valid_df = pd.read_csv(os.path.join(dataset_path, 'im2latex_validate.csv'))\n",
    "test_df  = pd.read_csv(os.path.join(dataset_path, 'im2latex_test.csv'))\n",
    "\n",
    "# Cleaning the test data as it has some NaN values\n",
    "test_df = test_df.dropna(subset=['formula'])\n",
    "\n",
    "# Build character vocabulary\n",
    "all_texts = pd.concat([train_df['formula'], valid_df['formula'], test_df['formula']])\n",
    "unique_chars = set(''.join(all_texts))\n",
    "\n",
    "char_to_num = {char: idx for idx, char in enumerate(sorted(unique_chars))}\n",
    "num_to_char = {idx: char for char, idx in char_to_num.items()}\n",
    "vocab_size = len(char_to_num)\n",
    "\n",
    "print(f\"Vocabulary Size: {vocab_size}\")\n",
    "print(f\"Example mapping: {list(char_to_num.items())[:10]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f26726",
   "metadata": {},
   "source": [
    "#### Defineing a custome data generator function with CTC inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe174bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CTCDataGenerator(Sequence):\n",
    "    def __init__(self, dataframe, images_dir, batch_size, img_height, img_width, datagen, max_label_length=100, shuffle=True):\n",
    "        self.dataframe = dataframe\n",
    "        self.images_dir = images_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.img_height = img_height\n",
    "        self.img_width = img_width\n",
    "        self.datagen = datagen\n",
    "        self.shuffle = shuffle\n",
    "        self.indices = np.arange(len(self.dataframe))\n",
    "        self.max_label_length = max_label_length\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.dataframe) / self.batch_size))\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "\n",
    "    def encode_label(self, text):\n",
    "        return [char_to_num[char] for char in text]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        batch_indices = self.indices[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        batch_filenames = self.dataframe.iloc[batch_indices]['filename'].values\n",
    "        batch_labels_text = self.dataframe.iloc[batch_indices]['latex'].values\n",
    "\n",
    "        batch_images = []\n",
    "        batch_labels = []\n",
    "        label_lengths = []\n",
    "\n",
    "        for filename, label_text in zip(batch_filenames, batch_labels_text):\n",
    "            img_path = os.path.join(self.images_dir, filename)\n",
    "            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "            img = cv2.resize(img, (img_width, img_height))\n",
    "            img = np.expand_dims(img, axis=-1)\n",
    "            batch_images.append(img)\n",
    "\n",
    "            encoded_label = self.encode_label(label_text)\n",
    "            batch_labels.append(encoded_label)\n",
    "            label_lengths.append(len(encoded_label))\n",
    "\n",
    "        batch_images = np.array(batch_images)\n",
    "        batch_images = self.datagen.flow(batch_images, batch_size=self.batch_size, shuffle=False).next()\n",
    "\n",
    "        batch_labels_padded = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "            batch_labels, \n",
    "            maxlen=self.max_label_length, \n",
    "            padding='post', \n",
    "            value=len(char_to_num)  # optional\n",
    "        )\n",
    "\n",
    "        feature_width = self.img_width // 4  # adjust according to CNN pooling\n",
    "        input_lengths = np.ones((self.batch_size, 1)) * feature_width\n",
    "        label_lengths = np.expand_dims(np.array(label_lengths), axis=-1)\n",
    "\n",
    "        inputs = {\n",
    "            'input_image': batch_images,\n",
    "            'labels': batch_labels_padded,\n",
    "            'input_length': input_lengths,\n",
    "            'label_length': label_lengths\n",
    "        }\n",
    "        outputs = {'ctc': np.zeros([self.batch_size])}\n",
    "\n",
    "        return inputs, outputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01c7e7b",
   "metadata": {},
   "source": [
    "#### Setting up data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e89af4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmentation settings\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0.1\n",
    ")\n",
    "\n",
    "valid_datagen = ImageDataGenerator(\n",
    "    rescale=1./255\n",
    ")\n",
    "\n",
    "# Generator instances\n",
    "batch_size = 32\n",
    "img_height = 192\n",
    "img_width = 192\n",
    "\n",
    "train_generator = CTCDataGenerator(train_df, images_path, batch_size, img_height, img_width, train_datagen)\n",
    "valid_generator = CTCDataGenerator(valid_df, images_path, batch_size, img_height, img_width, valid_datagen)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be930edd",
   "metadata": {},
   "source": [
    "#### Building the CRNN model with CTC Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba85f362",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-26 18:54:13.543778: W tensorflow/core/framework/op_kernel.cc:1829] UNKNOWN: JIT compilation failed.\n",
      "2025-04-26 18:54:13.543819: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: UNKNOWN: JIT compilation failed.\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "{{function_node __wrapped__Sign_device_/job:localhost/replica:0/task:0/device:GPU:0}} JIT compilation failed. [Op:Sign] name: ",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mUnknownError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 22\u001b[39m\n\u001b[32m     19\u001b[39m x = layers.Reshape(target_shape=new_shape)(x)\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# RNN\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m x = \u001b[43mlayers\u001b[49m\u001b[43m.\u001b[49m\u001b[43mBidirectional\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayers\u001b[49m\u001b[43m.\u001b[49m\u001b[43mLSTM\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_sequences\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[38;5;66;03m# Output layer\u001b[39;00m\n\u001b[32m     25\u001b[39m x = layers.Dense(vocab_size + \u001b[32m1\u001b[39m, activation=\u001b[33m'\u001b[39m\u001b[33msoftmax\u001b[39m\u001b[33m'\u001b[39m)(x)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/mathink/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    120\u001b[39m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    124\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/mathink/lib/python3.12/site-packages/keras/src/backend/tensorflow/numpy.py:2062\u001b[39m, in \u001b[36msign\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m   2060\u001b[39m     x = tf.cast(x, \u001b[33m\"\u001b[39m\u001b[33mint32\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   2061\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m tf.cast(tf.sign(x), ori_dtype)\n\u001b[32m-> \u001b[39m\u001b[32m2062\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[43m.\u001b[49m\u001b[43msign\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mUnknownError\u001b[39m: {{function_node __wrapped__Sign_device_/job:localhost/replica:0/task:0/device:GPU:0}} JIT compilation failed. [Op:Sign] name: "
     ]
    }
   ],
   "source": [
    "def ctc_lambda_func(args):\n",
    "    y_pred, labels, input_length, label_length = args\n",
    "    return K.ctc_batch_cost(labels, y_pred, input_length, label_length)\n",
    "\n",
    "# Inputs\n",
    "input_image = layers.Input(shape=(img_height, img_width, 1), name='input_image')\n",
    "labels = layers.Input(name='labels', shape=[None], dtype='float32')\n",
    "input_length = layers.Input(name='input_length', shape=[1], dtype='int64')\n",
    "label_length = layers.Input(name='label_length', shape=[1], dtype='int64')\n",
    "\n",
    "# CNN\n",
    "x = layers.Conv2D(32, (3,3), activation='relu', padding='same')(input_image)\n",
    "x = layers.MaxPooling2D(pool_size=(2,2))(x)\n",
    "x = layers.Conv2D(64, (3,3), activation='relu', padding='same')(x)\n",
    "x = layers.MaxPooling2D(pool_size=(2,2))(x)\n",
    "\n",
    "# Reshape\n",
    "new_shape = (img_width // 4, (img_height // 4) * 64)\n",
    "x = layers.Reshape(target_shape=new_shape)(x)\n",
    "\n",
    "# RNN\n",
    "x = layers.Bidirectional(layers.LSTM(128, return_sequences=True))(x)\n",
    "\n",
    "# Output layer\n",
    "x = layers.Dense(vocab_size + 1, activation='softmax')(x)\n",
    "\n",
    "# CTC loss\n",
    "ctc_loss = layers.Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')([x, labels, input_length, label_length])\n",
    "\n",
    "# Model\n",
    "model = models.Model(inputs=[input_image, labels, input_length, label_length], outputs=ctc_loss)\n",
    "\n",
    "model.compile(optimizer='adam')\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc3b594",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mathink",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
